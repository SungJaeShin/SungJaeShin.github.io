---
layout: post
title: Light Detection And Ranging (=LiDAR)
date: 2020-08-02 16:14:53
---

## About LiDAR
### LiDAR 명칭
LiDAR는 __<u>"Light Detection And Ranging"</u>__ 의 약어이고 때로는 __<u>"Laser Detection And Ranging"</u>__ 이라는 이름으로 사용된다.

<br>
### What is LiDAR?
기본적으로 LiDAR Sensor는 목표물에 특정 패턴으로 __빛을 쏘아 목표물의 반사광인 반사된 반송 신호 들을 바탕으로 정보(특징)를(을) 추출__ 하는 것을 보여주고 있다.  <br>
- 정보 : 사물까지의 거리(Depth), 물질의 분포, 농도의 특성(Intensity)
- 추출 : 펄스 전력, 왕복 시간, 위상 변이, 펄스폭 등 빛 신호에서 정보를 추출하는데 일반적으로 쓰이는 파라미터임

<br>

LiDAR Sensor System의 구성은 응용 분야에 따라 때로는 매우 복잡하게 구성되지만, 기본적인 구성은 [그림 1]에 보인 바와 같이 레이저 송신부, 레이저 검출부, 신호 수집 및 처리와 데이터를 송수신하기 위한 부분으로 단순하게 구분될 수 있다. [그림 1]에서 보여준 방식은 ToF(=Time of Flight) 방식인데 이는 Laser가 펄스 신호를 방출하여 측정 범위 내에 있는 물체들로부터의 반사 펄스 신호들이 수신기에 도착하는 시간을 측정함으로써 거리를 측정하는 방식이다.

<br>
<center><img src="https://github.com/SungJaeShin/SungJaeShin.github.io/blob/master/imgs/slam/sensor/LiDAR-1.PNG?raw=true" width="30%" height="30%"></center>

<br>
### Properties of LiDAR
- LiDAR마다 다르지만 Velodyne HDL-64E의 경우에는 측정범위가 1m에서 많게는 120m까지 측정할 수 있다. <br>
- LiDAR는 레이저 광을 조준할 수 있는 능력과 905~1550nm의 짧은 파장 때문에 LiDAR의 적외선 공간 분해능은 0.1&#176; 단위까지 나눌 수 있다. (&#8756; 이는 Back-End Processing 없이도 물체들의 특징을 한 정면으로 3D 묘사할 수 있다는 것이다.) <br>
- LiDAR마다 다르지만 대체로 LiDAR는 넓은 FoV(=Field of View)를 가지고 있다. Velodyne의 경우에는 360&#176;의 FoV를 가진다. <br>
- LiDAR는 야간의 경우에도 매우 높은 성능을 낼 수 있다. <br>
- LiDAR는 비, 안개, 눈 등의 악천후 조건에서 성능이 하락한다. 광 조건에 영향을 받기 쉽다. <br>
  &#8658;실제로는 엄청난 폭우나 눈이 아닌 경우에는 LiDAR로 Detecting이 잘 되는 것으로 알고 있다.<br>
- LiDAR

<br>
### What is Intensity?
여기서 __<u>"Intensity"</u>__ 라는 말이 있는데 이는 반사광의 정보 중 하나이다. 이는 쉽게 생각하면 __반사광이 주는 빛의 세기 및 반사되는 정도__ 이라고 생각하면 편하다. 쉽게 예를 들면 다음과 같다. 표지판의 경우 반사를 잘할 수 있도록 만들어졌는데 이는 intensity가 매우 높다고 생각할 수 있다. 이 경우 LiDAR에서 받는 정보는 많은 빛의 양을 가지므로 큰 Value를 줄 것이다. 반대로 차선과 같은 경우는 반사를 거의 안하고 흡수하므로 intensity사 매우 낮게 나타남을 알 수 있는 예시를 들 수 있다. 하지만, 신기하게도 하얀색의 차선은 높은 intensity의 결과를 주므로 Scan의 결과를 보면 차선이 선명하게 찍히는 것을 볼 수 있다. <br>
물체를 Detect하지 못하는 경우(=PointCloud가 찍히지 않는 경우)도 intensity를 이용하여 생각해볼 수 있다. 이 경우는 __intensity의 값이 '0'이라는 의미__ 가 되고 이는 __반사광이 주는 빛이 없고 다 흡수했다는 의미__ 로 해석될 수 있다. 따라서 LiDAR로는 측정할 수 없게 된다.
intensity는 낮이든 밤이든 일정한 값을 가지는 특성을 가지고 있기 때문에 상당히 Robust한 상태를 만들어주는 역할을 한다. LiDAR에서 쏜 빛만이 LiDAR에서 감지를 할 수 있기 때문에 유용하게 사용할 수 있는 특성이 있다.

### LiDAR Message Type
- sensor_msgs/PointCloud
- sensor_msgs/PointCloud2  

여기서 공간 분해능은 다른 말로 공간 해상도(=Spatial Resolution)이라고도 하는데 이는 검출할 수 있는 가장 작은 대상의 크기라는 의미가 된다. 즉, LiDAR에서 0.1도 마다 point들을 검출할 수 있다는 의미가 된다.
http://jun.hansung.ac.kr/SI/notes/RS%20Lecture%20Notes%202%281%20of%203%29-new.pdf
또한, LiDAR은 넓은 FOV를 가지고 있고 수직 FOV에서 Ladar보다 더 뛰어나다. 각도 분해능에서도 Radar보다 우위에 있다.
야간의 경우에는 LiDAR시스템은 매우 높은 성능을 낼 수 있다.
http://www.epnc.co.kr/news/articleView.html?idxno=82099
Disadvantage : LiDAR는 비, 안개, 눈 등에 날씨 조건에서 성능이 하락한다. 그래서 이런 Radar를 이용하여 1550nm의 적외선 파장을 이용하면 악천후에서 LiDAR의 성능을 개선할 수 있다. 광 조건에 영향을 받기 쉽다.


기계식 LiDAR : 회전 어셈블리를 이용해 360도 FOV를 만들어낸다. FOV 이상으로 SNR이 높지만 몸집이 커지게 된다. 최근에는 이런 크기가 줄고 있다.
고정형 LiDAR : 회전하는 기계식 컴포넌트들이 없고 FOV는 줄어들기 때문에, 더욱 저렴하지만 차량 전방 후방 측면의 여러 채널들을 이용해 그 데이터들을 융합하면 기계식 LiDAR에 필적하는 FOV를 만들 수 있다.

LiDAR Odometry라는 것이 있는데 이는 t에서의 scan data와 t+1에서의 scan data끼리 계속 정합을 하여 하나의 odometry를 이용하게 된다. 이때의 odometry는 t와 t+1 사이의 transformation matrix가 되는 것이다. (각 Local Coordinate 사이의 TF가 odom이 된다.) 이때, odom으로 쓰기 어려운 환경이 존재한다. 이는 Feature가 거의 없고 일정한 환경에서는 같은 장소라고 판단하기 떄문에 Registration이 어렵게 된다. 예를 들면 터널 같은 공간이나 일정한 복도를 지날 때를 들 수 있다. 이 문제를 해결하게 된다면 실내에서도 충분히 사용할 수 있는 odometry가 된다. 아니면 IMU까지 사용을 함으로서 (Fusing) 이 문제를 해결할 수 있게 된다.
Image를 이용하는 것이 마찬가지로 Visual Odometry와 같은 의미가 되는 것이다.
RANSAC을 이용한 Scan Matching을 하는 것도 생각해보면 다음과 같다. 2개의 Scan Data를 이용하여 여기서 임의의 Sample Points 들을 뽑아서 생각해보면 각 point 들끼리 거리를 구해서 가장 가까운 것들을 만들고 Threshold 기준으로 멀리 있으면 outlier 안에 있으면 Inlier로 선택을 하여 구분을 하게 된다. 이런식으로 Outlier에 있는 비율이 더 많게 되면 그 Scan Data는 Matching을 못하고 다른 Sample들을 찾게 된다.
LOAM: Lidar Odometry and Mapping in Real-time 이 논문 참고
초음파는 몇 미터만 벗어나도 대기 중에서 크게 감쇠하게 된다. 따라서 초음파 센서는 주로 단거리 물체 감지에 쓰인다.
카메라는 비용 효율적이고 쉽게 구할 수 있는 센서이지만, 유용한 정보를 추출하려면 상당한 프로세싱이 필요하며 주변의 광 조건에 크게 좌우된다. 카메라는 ‘컬러를 인지하는’ 유일한 기술이라는 점에서 특별하다. 차선유지 보조 기능이 있는 자동차는 이 기술에 카메라를 사용한다.
intensity data using application?
https://desktop.arcgis.com/en/arcmap/10.3/manage-data/las-dataset/what-is-intensity-data-.htm
LiDAR intensity is recorded as the return strength of a laser beam
LiDAR systems, it is a bi-product, provided as an integer number between 1-256. This number varies with the composition of the surface object reflecting the laser beam.
실제 자율주행에 적용을 시켜보면, 이는 Threshold 값을 주어서 그보다 위에 있으면 표지판이라고 생각을 해준다. 그러면, 실제로 Intensity가 낮은 것들은 일반적인 건물 벽, 나무, Lane 등이 있고 나머지 표지판은 높기 때문에 이 intensity를 이용하는 경우도 있다.
그리고 intensity가 날씨의 영향을 잘 받지 않는 값이고 야간이나 낮에도 그 값이 일정하게 유지되기 때문에 이는 Robust한 영향을 줄 수 있는 특징들을 가지고 있다.
Velodyne의 경우에는 1-255까지의 intensity의 Value로 나타내기도 한다.
사실 폭우나 눈이 내리지 않는다면 기본적인 LiDAR에 대해서 Odometry나 pointcloud를 잘 얻을 수 있게 된다.

http://www.6d-vision.com/home/prinzip ego-motion estimation
calibration
https://geodetics.com/lidar-intensity-applications/ LiDAR intensity application
https://patents.google.com/patent/KR20170064652A/ko ego-motion estimation

curvature을 이용하여 edge와 planar를 구분하는 논문이 LOAM이라는 논문인데 이는 registration을 이용할 때 매우 유용하게 쓰인다. 하지만 이 또한 나온지 좀 된 논문이라 더 최신의 LOAM을 이용하여 확장된 논문들을 참고한다.

또한 PointCloud들은 각 Channel마다 360로 point들을 뽑아오는데 같은 radius라면 같은 z축임을 알 수 있는 논문들도 있다고 한다. 이는 연구에 도움이 많이 될 것이라고 생각한다.

https://pcl.readthedocs.io/projects/tutorials/en/latest/#sample-consensus
## 생각해보기


## Appendix A
- 파장과 주파수 사이 관계
  * 파장(&#955;) = 광속(c) / 주파수(f)

<br>

- 주파수가 높은 전파
  * 빛과 같이 직진성이 강해서 특정 방향으로 송신하는데 유리
  * 많은 정보를 실어 보낼 수 있음
  * 비가 오거나 안개가 낀 날은 공기 중에 물방울과 수증기 때문에 전파가 흡수되어 멀리 가지 못함

<br>

- 주파수가 낮은 전파
  * 직진성은 약하지만 장애물을 뛰어넘는 특성이 좋음
  * 넓은 지역을 커버하는데 유리
  * 실을 수 있는 정보량이 적음


<br>
## Appendix B



<br>
## Reference
[Site] <br>
- Spatial Resolution : http://jun.hansung.ac.kr/SI/notes/RS%20Lecture%20Notes%202%281%20of%203%29-new.pdf <br>
- LiDAR : http://www.epnc.co.kr/news/articleView.html?idxno=82099 <br>
- LiDAR : https://ettrends.etri.re.kr/ettrends/138/0905001782/134-143_27-6.pdf <br>
- Intensity : https://desktop.arcgis.com/en/arcmap/10.3/manage-data/las-dataset/what-is-intensity-data-.htm <br>
- Frequency :  https://m.blog.naver.com/PostView.nhn?blogId=kofreeguide&logNo=220151167456&proxyReferer=https:%2F%2Fwww.google.com%2F <br>


<br>
[Paper]
- LOAM(LiDAR Odometry And Mapping)
  * Zhang, J. and Singh, S., “LOAM: Lidar Odometry and Mapping in Real-time," in Proc. Robotics: Science and Systems (RSS), 2014.
